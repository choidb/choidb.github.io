---
title: '다중선형회귀(Linear Regression)'
use_math: true
categories:
  - ml
---

**목차**  
[1. 데이터 분리](#1-데이터-분리)  
[2. 다중선형회귀모델](#2-다중선형회귀모델)  
[3. 회귀모델을 평가하는 평가지표들](#3-회귀모델을-평가하는-평가지표들evaluation-metrics)  
[4. 과적합, 과소적합](#4-과적합overfitting과-과소적합underfitting)  
[5. 분산 편향 트레이드 오프](#5-분산편향-트레이드오프)  

---
* Contents
1. 학습, 테스트 데이터 분리 이유
2. 다중 선형 회귀
3. 과적합 / 과소적합
4. 편향 / 분산의 트레이드오프 개념

---

## 1. 데이터 분리
* 데이터를 훈련/테스트 데이터로 나누어야 우리가 만든 모델의 예측 성능을 제대로 평가 가능함.
* 시간변화에 관계없을 경우
  * 무작위로 훈련/테스트 데이터셋으로 나눔
* 시계열 데이터의 경우는 무작위로 섞으면 안됨.

## 2. 다중선형회귀모델
* 기준모델(특성 없음)
* 2 개 이상의 특성들을 사용

## 3. 회귀모델을 평가하는 평가지표들(evaluation metrics)
* MSE (Mean Squared Error) = 
$\frac{1}{n}\sum_{i=1}^{n}(y_{i} - \hat{y_{i}})^{2}$
* MAE (Mean absolute error) = $\frac{1}{n}\sum_{i=1}^{n}\left \vert y_{i} - \hat{y_{i}} \right \vert$
* RMSE (Root Mean Squared Error) = 
$\sqrt{MSE}$
* R-squared (Coefficient of determination) = 
$1 - \frac{\sum_{i=1}^{n}(y_{i} - \hat{y_{i}})^{2}}{\sum_{i=1}^{n}(y_{i} - \bar{y_{i}})^{2}} = 1 - \frac{SSE}{SST} = \frac {SSR}{SST}$

- 참고
    - SSE(Sum of Squares `Error`, 관측치와 예측치 차이): $\sum_{i=1}^{n}(y_{i} - \hat{y_{i}})^{2}$
    - SSR(Sum of Squares due to `Regression`, 예측치와 평균 차이): $\sum_{i=1}^{n}(\hat{y_{i}} - \bar{y_{i}})^{2}$
    - SST(Sum of Squares `Total`, 관측치와 평균 차이): $\sum_{i=1}^{n}(y_{i} - \bar{y_{i}})^{2}$ , SSE + SSR

* $R^2$ 외에, MAE는 단위 유닛이 같으므로 보다 해석에 용이한 장점이 있고, MSE는 제곱을 하기 때문에 특이값에 보다 민감 합니다. RMSE는 MSE를 실제값과 유사한 단위로 변화시켜주는 장점이 있습니다.

[회귀의 오류 지표 알아보기](https://partrita.github.io/posts/regression-error/)

## 4. 과적합(Overfitting)과 과소적합(Underfitting)
* 테스트데이터에서 만들어내는 오차를 일반화 오차라 함
* 훈련데이터에서와같이 테스트데이터에서도 좋은 성능을 내는 모델은 일반화가 잘 된 모델이라 함
* 모델이 너무 훈련데이터에 과하게 학습(과적합)을 하지 않도록 하는 많은 일반화 방법들이 있음
* 과적합은 모델이 훈련데이터에만 특수한 성질을 과하게 학습해 일반화를 못해 결국 테스트데이터에서 오차가 커지는 현상
* 과소적합은 훈련데이터에 과적합도 못하고 일반화 성질도 학습하지 못해, 훈련/테스트 데이터 모두에서 오차가 크게 나오는 경우

## 5. 분산/편향 트레이드오프
* 분산이 높은경우는, 모델이 학습 데이터의 노이즈에 민감하게 적합하여 테스트데이터에서 일반화를 잘 못하는 경우 즉 과적합 상태
* 편향이 높은경우는, 모델이 학습 데이터에서, 특성과 타겟 변수의 관계를 잘 파악하지 못해 과소적합 상태
* 편향도 적고 분산도 적은 모델이 좋은 모델이다.

* Sklearn의 PolynomialFeatures는 다항회귀모델을 쉽게 구현하도록 도와줌.
  * 다항 특성(polynomial features)을 방정식에 추가하는 것
  * 다항 특성 = 상호작용특성(interaction features)
